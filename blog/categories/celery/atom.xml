<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类: celery | 小明明s à domicile]]></title>
  <link href="http://dongweiming.github.com/blog/blog/categories/celery/atom.xml" rel="self"/>
  <link href="http://dongweiming.github.com/blog/"/>
  <updated>2016-10-24T14:35:08+08:00</updated>
  <id>http://dongweiming.github.com/blog/</id>
  <author>
    <name><![CDATA[Dongweiming]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[speakerdeck]]></title>
    <link href="http://dongweiming.github.com/blog/archives/speakerdeck/"/>
    <updated>2014-04-18T16:49:00+08:00</updated>
    <id>http://dongweiming.github.com/blog/archives/speakerdeck</id>
    <content type="html"><![CDATA[<h4 id="section">前言</h4>

<p>今天是在Ad的最后一天,本来准备了一个分享.关于业务中一些吐槽和我一些trick的用法, 有兴趣的可以下载<a href="https://github.com/dongweiming/speakerdeck">speakerdeck</a></p>

<h4 id="section-1">主题</h4>

<ol>
  <li>celery celery2/celery3, py-amqp, kombu的用法, celery和djangocelery的集合</li>
  <li>expect 使用expect自动登录复杂的服务器</li>
  <li>mapreduce 一个并行处理文件的例子,说明使用python跑mapreduce多么厉害</li>
  <li>portforward 端口转发</li>
  <li>restapi 我眼中的restapi(pdf)</li>
  <li>tornado 使用tornado一部非阻塞</li>
</ol>

<p>演示的tmux脚本:</p>

<p>```
#!/bin/bash
SESSION=$USER
COMMAND=’http Space http://localhost:8000/sleep’</p>

<p>tmux new-session -d -s $SESSION</p>

<p>tmux new-window -t $SESSION -n ‘Logs’
tmux split-window -h
tmux select-pane -t 0
tmux send-keys $COMMAND C-m
tmux select-pane -t 1
tmux send-keys $COMMAND C-m
tmux split-window -v
tmux send-keys $COMMAND C-m
tmux select-pane -t 0
tmux split-window -v
tmux send-keys $COMMAND C-m
# Attach to session
tmux attach-session -t $SESSION
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用celery之怎么让celery跑起来]]></title>
    <link href="http://dongweiming.github.com/blog/archives/how-to-use-celery/"/>
    <updated>2013-11-24T16:46:00+08:00</updated>
    <id>http://dongweiming.github.com/blog/archives/how-to-use-celery</id>
    <content type="html"><![CDATA[<h4 id="section">前言</h4>

<p>自从发了上次的文章<a href="http://www.dongwm.com/archives/shi-yong-celeryzhi-shen-ru-celerypei-zhi/">使用celery之深入celery配置</a>,
有一些网友再问我怎么让celery跑起来. 其实说来也是,celery在新手眼里真的是比较重量级,不好懂,今天先让他跑起来吧
本文大部分代码和使用方法都可以在celery官网看到</p>

<h4 id="section-1">我想要的效果</h4>

<p>我想实现一个定时任务, 每3个小时的12分启动,假如是定时任务大概是这样的:</p>

<p><code>
12 */3 * * * python /where/is/the/path/that.py
</code></p>

<h4 id="mq">选择MQ</h4>

<p>使用消息队列其实就是为了给任务一个时序,保证任务消息不丢失,想想你的一个任务是关乎公司核心业务,犹豫某种原因失败或者丢失怎么办?
celery就需要这个消息的存储,我这里还是选择rabbitmq  mongodb,redis都无所谓 只是存储的位置的问题.
选择其他的工具没有远程控制和监控</p>

<p>写法就是:</p>

<p><code>
BROKER_URL = 'amqp://myuser:mypassword@localhost:5672/vhost'
</code></p>

<p>其中可以这样解析</p>

<p><code>
amqp://user:password@hostname:port/vhost
</code></p>

<p>vhost是命名空间,就像网站的子域名,在这里由于权限控制我们需要先创建账号和密码</p>

<p><code>
$ rabbitmqctl add_user myuser mypassword
$ rabbitmqctl add_vhost myvhost
$ rabbitmqctl set_permissions -p myvhost myuser ".*" ".*" ".*"
</code></p>

<h4 id="taskspy">编写tasks.py脚本</h4>

<p>```
from celery import Celery</p>

<p>app = Celery(‘tasks’, broker=’amqp://myuser:mypassword@localhost:5672/vhost’)</p>

<p>@app.task
def add(x, y):
    return x + y
```
#### 简单的使用</p>

<p><code>
$celery -A tasks worker --loglevel=debug
</code></p>

<p>-A指定的就是任务的程序 tasks.py  worker表示他是一个执行任务角色. 后面的记录日志类型,默认是info</p>

<p>这个时候,你可以在当前目录下使用python交互模式生成一个任务</p>

<p><code>
&gt;&gt;&gt; from tasks import add
&gt;&gt;&gt; add.delay(4, 4)
</code></p>

<p>这个时候可以看见上面的日志里面多了一些消息,然后里面多了这个任务的信息,比如下面这样:</p>

<p><code>
[2013-11-24 17:11:59,369: INFO/MainProcess] Received task: tasks.add[f27994b0-3628-43a1-b136-540a360e3d64]
[2013-11-24 17:11:59,371: INFO/MainProcess] Task tasks.add[f27994b0-3628-43a1-b136-540a360e3d64] succeeded in 0.00102571400021s: 8
</code></p>

<p>可以看见你的任务被执行了</p>

<h4 id="python-">假如我使用python的包, 就像一个应用,让代码结构化一些</h4>

<p><code>
$tree proj
proj
├── __init__.py
├── celery.py
└── tasks.py
</code></p>

<p><code>
$cat proj/celery.py
from __future__ import absolute_import
from celery import Celery
app = Celery('proj',
              broker='amqp://myuser:mypassword@localhost:5672/vhost',
              backend='amqp://',
              include=['proj.tasks'])
app.conf.update(CELERY_TASK_RESULT_EXPIRES=3600,)
if __name__ == '__main__':
    app.start()
</code></p>

<p>上面的broker就是消息存储的地址
backend是存储任务执行情况的,比如正在执行，执行失败, 已经执行结果.
include表示执行的任务的代码都放在哪个程序里面,比如这里的proj.tasks就是proj/tasks.py</p>

<p>```
$cat proj/tasks.py
from <strong>future</strong> import absolute_import</p>

<p>from proj.celery import app</p>

<p>@app.task
def add(x, y):
    return x + y
```</p>

<p>其中的app.task是一个装饰器, 你可以在tasks.py里面加很多函数,但是celery只会找带这个装饰器的函数当成一种任务去执行
你可以有多个这样的脚本,只要在上面的celery.py的include的列表中指定</p>

<p>好吧 我们可以这样启动</p>

<p><code>
$celery worker --app=proj -l info
</code></p>

<p>proj 就是我们刚才应用的项目目录</p>

<h4 id="section-2">给我们的项目任务放到特定的队列</h4>

<p>可能你有很多的任务,但是你希望某些机器跑某些任务, 你可以希望有些任务优先级比较高,而不希望
先进先出的等待. 那么需要引入一个队列的问题. 也就是说在你的broker的消息存储里面有一些队列，他们并行运行，但是worker只从对应
的队列里面取任务.</p>

<p>我们要修改配置</p>

<p><code>
$cat proj/celery.py
from __future__ import absolute_import
from celery import Celery
app = Celery('proj',
              broker='amqp://myuser:mypassword@localhost:5672/vhost',
              backend='amqp://',
              include=['proj.tasks'])
app.conf.update(
    CELERY_ROUTES = {
            'proj.tasks.add': {'queue': 'hipri'},
                },
                )
if __name__ == '__main__':
    app.start()
</code></p>

<p><code>
celery -A proj worker -Q hipri #这个worker只处理hipri这个队列的任务
</code></p>

<p>你会发现add这个函数任务被放在一个叫做’hipri’的队列里面，想要执行那么也需要改:</p>

<p><code>
from proj.tasks import add
add.apply_async((2, 2), queue='hipri')
</code></p>

<h4 id="beat">使用beat自动调度</h4>

<p>想想吧. 目前还是交互模式去手动执行, 我们要是想crontab的定时生成和执行,那么就是celery beat干的事情</p>

<p>```
from <strong>future</strong> import absolute_import</p>

<p>from datetime import timedelta
from celery import Celery</p>

<p>app = Celery(‘proj’,
             broker=’amqp://myuser:mypassword@localhost:5672/vhost’,
             backend=’amqp://’,
              include=[‘proj.tasks’])</p>

<p>app.conf.update(
    CELERY_ROUTES = {
        ‘proj.tasks.add’: {‘queue’: ‘hipri’},
    },</p>

<pre><code>CELERYBEAT_SCHEDULE = {
    "add": {
            "task": "proj.tasks.add",
            "schedule": timedelta(seconds=10),
            "args": (16, 16)
            }, },
            )
</code></pre>

<p>if <strong>name</strong> == ‘<strong>main</strong>’:
    app.start()</p>

<p>```</p>

<p>注意发现了一个CELERYBEAT_SCHEDULE,里面的调度其实就是表示10秒生成一次,worker启动方法一样,
这里启动beat,他就是按时生成任务发到MQ里面,让worker取走去执行</p>

<p><code>
celery -A proj beat
</code></p>

<p>其实也可以在worker命令中加-B</p>

<p><code>
celery -A proj worker -B -Q hipri -l debug
</code></p>

<p>刚才的CELERYBEAT_SCHEDULE也可以使用crontab的风格，比如我说的没3小时的12分就可以这样:</p>

<p>```
from celery.schedules import crontab</p>

<p>CELERYBEAT_SCHEDULE = {
        “add”: {
                “task”: “tasks.add”,
                “schedule”: crontab(hour=”*/3”, minute=12),
                “args”: (16, 16),
                },
            }
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用celery之深入celery配置]]></title>
    <link href="http://dongweiming.github.com/blog/archives/shi-yong-celeryzhi-shen-ru-celerypei-zhi/"/>
    <updated>2013-08-24T14:08:00+08:00</updated>
    <id>http://dongweiming.github.com/blog/archives/shi-yong-celeryzhi-shen-ru-celerypei-zhi</id>
    <content type="html"><![CDATA[<h4 id="section">前言</h4>

<p>celery的官方文档其实相对还是写的很不错的.但是在一些深层次的使用上面却显得杂乱甚至就没有某些方面的介绍, 通过我的一个测试环境的settings.py来说明一些使用celery的技巧和解决办法</p>

<h4 id="amqp">amqp交换类型</h4>

<p>其实一共有4种交换类型，还有默认类型和自定义类型. 但是对我们配置队列只会用到其中之三，我来一个个说明，英语好的话可以直接去看英文文档</p>

<p>首先思考一下流程:</p>

<ol>
  <li>
    <p>celerybeat生成任务消息，然后发送消息到一个exchange(交换机)</p>
  </li>
  <li>
    <p>交换机决定那个(些)队列会接收这个消息，这个其实就是根据下面的exchange的类型和绑定到这个交换机所用的bindingkey</p>
  </li>
</ol>

<p>我们这里要说的其实就是怎么样决定第二步谁接收的问题</p>

<ol>
  <li>Direct Exchange</li>
</ol>

<p>如其名，直接交换，也就是指定一个消息被那个队列接收， 这个消息被celerybeat定义个一个routing key，如果你发送给交换机并且那个队列绑定的bindingkey 那么就会直接转给这个队列</p>

<ol>
  <li>Topic Exchange</li>
</ol>

<p>你设想一下这样的环境(我举例个小型的应该用场景): 你有三个队列和三个消息, A消息可能希望被X,Y处理,B消息你希望被,X,Z处理,C消息你希望被Y,Z处理.并且这个不是队列的不同而是消息希望被相关的队列都去执行,看一张图可能更好理解:</p>

<p><img src="https://access.redhat.com/site/documentation/resources/docs/en-US/Red_Hat_Enterprise_MRG/1.1/html/Messaging_User_Guide/images/topic-exchange.png" alt="" /></p>

<p>对，Topic可以根据同类的属性进程通配, 你只需要routing key有’.’分割:比如上图中的usa.news, usa.weather, europe.news, europe.weather</p>

<ol>
  <li>Fanout Exchange</li>
</ol>

<p>先想一下广播的概念, 在设想你有某个任务，相当耗费时间，但是却要求很高的实时性,那么你可以需要多台服务器的多个workers一起工作，每个服务器负担其中的一部分,但是celerybeat只会生成一个任务,被某个worker取走就没了,
所以你需要让每个服务器的队列都要收到这个消息.这里很需要注意的是:你的fanout类型的消息在生成的时候为多份,每个队列一份，而不是一个消息发送给单一队列的次数</p>

<h4 id="settingspy">我的settings.py</h4>

<p>这里只是相关于celery的部分:</p>

<p>```python
import djcelery
djcelery.setup_loader()</p>

<p>INSTALLED_APPS = (
    ‘django.contrib.auth’,
    ‘django.contrib.contenttypes’,
    ‘django.contrib.sessions’,
    ‘django.contrib.sites’,
    #’django.contrib.staticfiles’,
    ‘django.contrib.messages’,
    # Uncomment the next line to enable the admin:
    ‘django.contrib.admin’,
    ‘django.contrib.staticfiles’,
    # Uncomment the next line to enable admin documentation:
    # ‘django.contrib.admindocs’,
    ‘dongwm.smhome’,
    ‘dongwm.apply’,
    ‘djcelery’, # 这里增加了djcelery 也就是为了在django admin里面可一直接配置和查看celery
    ‘django_extensions’,
    ‘djsupervisor’,
    ‘django.contrib.humanize’,
    ‘django_jenkins’
)</p>

<p>BROKER_URL = ‘amqp://username:password@localhost:5672/yourvhost’</p>

<p>CELERY_IMPORTS = (
    ‘dongwm.smhome.tasks’,
    ‘dongwm.smdata.tasks’,
)</p>

<p>CELERY_RESULT_BACKEND = “amqp” # 官网优化的地方也推荐使用c的librabbitmq
CELERY_TASK_RESULT_EXPIRES = 1200 # celery任务执行结果的超时时间，我的任务都不需要返回结果,只需要正确执行就行
CELERYD_CONCURRENCY = 50 # celery worker的并发数 也是命令行-c指定的数目,事实上实践发现并不是worker也多越好,保证任务不堆积,加上一定新增任务的预留就可以
CELERYD_PREFETCH_MULTIPLIER = 4 # celery worker 每次去rabbitmq取任务的数量，我这里预取了4个慢慢执行,因为任务有长有短没有预取太多
CELERYD_MAX_TASKS_PER_CHILD = 40 # 每个worker执行了多少任务就会死掉，我建议数量可以大一些，比如200
CELERYBEAT_SCHEDULER = ‘djcelery.schedulers.DatabaseScheduler’ # 这是使用了django-celery默认的数据库调度模型,任务执行周期都被存在你指定的orm数据库中
CELERY_DEFAULT_QUEUE = “default_dongwm” # 默认的队列，如果一个消息不符合其他的队列就会放在默认队列里面</p>

<p>CELERY_QUEUES = {
    “default_dongwm”: { # 这是上面指定的默认队列
        “exchange”: “default_dongwm”,
        “exchange_type”: “direct”,
        “routing_key”: “default_dongwm”
    },
    “topicqueue”: { # 这是一个topic队列 凡是topictest开头的routing key都会被放到这个队列
        “routing_key”: “topictest.#”,
        “exchange”: “topic_exchange”,
        “exchange_type”: “topic”,
    },
    “test2”: { # test和test2是2个fanout队列,注意他们的exchange相同
        “exchange”: “broadcast_tasks”,
        “exchange_type”: “fanout”,
        “binding_key”: “broadcast_tasks”,
    },
    “test”: {
        “exchange”: “broadcast_tasks”,
        “exchange_type”: “fanout”,
        “binding_key”: “broadcast_tasks2”,
    },
}</p>

<p>class MyRouter(object):</p>

<pre><code>def route_for_task(self, task, args=None, kwargs=None):

    if task.startswith('topictest'):
        return {
            'queue': 'topicqueue',
        }
    # 我的dongwm.tasks文件里面有2个任务都是test开头
    elif task.startswith('dongwm.tasks.test'):
        return {
            "exchange": "broadcast_tasks",
        }
    # 剩下的其实就会被放到默认队列
    else:
        return None
</code></pre>

<h1 id="celeryroutes">CELERY_ROUTES本来也可以用一个大的含有多个字典的字典,但是不如直接对它做一个名称统配</h1>
<p>CELERY_ROUTES = (MyRouter(), )
```</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用celery之了解celery]]></title>
    <link href="http://dongweiming.github.com/blog/archives/shi-yong-celeryzhi-liao-jie-celery/"/>
    <updated>2013-08-10T20:12:00+08:00</updated>
    <id>http://dongweiming.github.com/blog/archives/shi-yong-celeryzhi-liao-jie-celery</id>
    <content type="html"><![CDATA[<h4 id="section">前言</h4>

<p>我想很多做开发和运维的都会涉及一件事:crontab, 也就是在服务器上设定定时任务,按期执行一些任务.但是假如你有上千台的服务器，
你有上千种任务,那么对于这个定时任务的管理恐怕是一件很头疼的事情.哪怕你只是几十个任务分配的不同的机器上怎么样合理的管理和实现以下功能呢:</p>

<ol>
  <li>查看定时任务的执行情况.比如执行是否成功，当前状态，执行花费的时间.</li>
  <li>一个友好的界面或者命令行下实现添加,删除任务</li>
  <li>怎么样简单实现不同的机器设定不同种任务,某些机器执行不同的队列</li>
  <li>假如你需要生成一个任务怎么样不阻塞剩下来的过程(异步了呗)</li>
  <li>怎么样并发的执行任务</li>
</ol>

<h4 id="section-1">几种选择</h4>

<ol>
  <li>有钱有人有时间自己实现一套,优点是完全符合公司业务的需要,有专门的团队维护和服务</li>
  <li>使用<a href="http://gearman.org/">Gearman</a>,听说过没用过，因为是C/java/perl,对我们这种python开发者或者运维来说,假如没有这方面经验之后没有能力了解底层实现和二次开发的能力</li>
  <li>使用<a href="http://python-rq.org/">rq</a>, rq是搞gitflow的那个作者写的，简介里面说的很清楚:Simple job queues for Python. 怕它不够复杂,但是假如业务没有那么复杂或者应用不是那么严格，完全可以尝试下</li>
  <li>好吧我选择了<a href="https://github.com/celery/celery">celery</a>, 现在用了快半年，可能是历史遗留问题,版本较低.有很多坑.但是很不错</li>
</ol>

<h4 id="section-2">消息队列</h4>

<p>RabbitMQ,ZeroMQ这样的消息队列总是出现在我们视线中, 其实意义是很简单: 消息就是一个要传送的数据,celery是一个分布式的任务队列.这个”任务”其实就是一种消息,
任务被生成到队列中，被RabbitMQ等容器接收和存储，在适当的时候又被要执行的机器把这个消息取走.</p>

<p>celery任务可以使用RabbitMQ/Redis/SQLAlchemy/Django的orm/Mongodb等等容器(这里叫做Broker).我使用的是RabbitMQ,因为作者在github主页的介绍里面很明确的写了这个</p>

<p>所谓队列,你可以设想一个问题,我有一大推的东西要执行,但是我并不是需要每个服务器都执行这个任务,因为业务不同嘛. 所以就要做个队列, 比如任务A,B,C A可以在X,Y服务器执行,
但是不需要或者不能在Z服务器上执行.那么在X,Y你启动worker(下面会说，其实就是消费者和生产者的消费者)加上这个队列,Z服务器就不需要指定这个队列,也就不会执行这个队列的任务</p>

<h5 id="celerydjangocelerydjango-celery">celery的原理,我这里的角度是django+celery+django-celery</h5>

<p>首先说一下流程:</p>

<ol>
  <li>使用django-celery或者直接操作数据库(settings.py里面指定)添加任务,设置的相关属性(包含定时任务的间隔)存入数据库.</li>
  <li>celerybeat通过djcelery.schedulers.DatabaseScheduler获取django内你设置的任务周期性的检查(默认5s),发现需要执行某任务讲其丢入你设置的broker(我这里是rabbitmq),他会更具settings.py的设置放到对应的队列</li>
  <li>在你启动了celery worker(以前是celeryd)的服务器上,根据worker也会定期(默认5s)去broker里面查找需要它执行的队列里面是否有任务</li>
  <li>当发现队列有要执行的任务,worker将它取出来执行,执行完的结果通过celerycam(默认30s,所以这个进程也要启动)写入django设置的数据库,更新了这个任务的状态.比如花费的时间</li>
</ol>

<h4 id="supervisor">supervisor进程管理</h4>

<p>不知道有没有人用过<a href="http://cr.yp.to/daemontools/supervise.html">supervise</a>，我以前经常在最初的项目开发中经常使用它监视我的程序,当程序死掉自动启动, <a href="https://github.com/Supervisor/supervisor">supervisor</a>确是一个
进程管理的工具，我在这里使用它管理celery的程序和uwsgi</p>

<p>粘贴下我的一个本地环境的配置,并直接进行一下说明:</p>

<p>```python
;程序名字
[program:celery-queue-fetch]
;程序要执行的命令, -Q 指定了生成和接受任务的队列,多个用都好分开 -c为workr的数量,原意为并发数量
command=python /home/dongwm/work/manage.py celery worker -E –settings=settings_local –loglevel=INFO -Q fetch_ -c 30
;程序执行时候所在目录
directory=/home/dongwm/work/
;执行程序使用的用户
user=dongwm
;启动的程序的实例数,默认是1
numprocs=1
stdout_logfile=/home/dongwm/work/celerylog/celery.log
stderr_logfile=/home/dongwm/work/celerylog/celery.log
;在启动supervisor时候自动启动
autostart=true
;当程序可能因为某些原因没有启动成功会自动重启
autorestart=true
;启动的等待时候,我想是为了重启能杀掉原来进程预留的时间
startsecs=10
;进程发送停止信号等待os返回SIGCHILD的时间
stopwaitsecs=10
;低优先级的会首先启动最后关闭
priority=998
;以下2句是为了保证杀掉进程和其子进程而不会只杀死其控制的程序主进程而留下子进程变为孤立进程的问题
stopsignal=KILL
stopasgroup=true</p>

<p>[program:celery-queue-feed]
command=python /home/dongwm/work/manage.py celeryd -E –settings=settings_local –loglevel=INFO -Q feed
directory=/home/dongwm/work/
user=dongwm
numprocs=1
stdout_logfile=/home/dongwm/work/celerylog/celery.log
stderr_logfile=/home/dongwm/work/celerylog/celery.log
autostart=true
autorestart=true
startsecs=10
stopwaitsecs=10
priority=998
stopsignal=KILL
stopasgroup=true</p>

<p>[program:celerycam]
;任务快照的间隔时间为10s
command=python /home/dongwm/work/manage.py celerycam -F 10 –settings=settings_local
directory=/home/dongwm/work/
user=dongwm
numprocs=1
stdout_logfile=/home/dongwm/work/celerylog/celerycam.log
stderr_logfile=/home/dongwm/work/celerylog/celerycam.log
autostart=true
autorestart=true
startsecs=5
stopwaitsecs=5
priority=998
stopsignal=KILL
stopasgroup=true</p>

<p>[program:celerybeat]
command=python /home/dongwm/work/manage.py celerybeat –settings=settings_real_old –loglevel=DEBUG
directory=/home/dongwm/work/
user=dongwm
numprocs=1
stdout_logfile=/home/dongwm/work/celerylog/celery_beat.log
stderr_logfile=/home/dongwm/work/celerylog/celery_beat.log
autostart=true
autorestart=true
startsecs=10
priority=999
stopsignal=KILL
stopasgroup=true</p>

<p>;这是supervisor官方的一个监控进程状态异常退出的脚本,我对它进行了较大的修改,这样在程序奇怪退出的时候会给我发邮件
[eventlistener:crashmail]
command=python /home/dongwm/superlance/superlance/crashmail.py -a -m ciici123@163.com
events=PROCESS_STATE_EXITED</p>

<p>[program:uwsgi]
user = dongwm
numprocs=1
command=/usr/local/bin/uwsgi -s /tmp/uwsgi-sandbox.sock –processes 4  –enable-threads \
     –pythonpath /home/dongwm/uwsgi –buffer-size 32768 –listen 100 –daemonize /home/dongwm/ulog/uwsgi_out.log
directory=/home/dongwm/work
autostart=true
autorestart=true
redirect_stderr=true
stopsignal=KILL
stopasgroup=true
```</p>

<h4 id="nginxuwsgi">nginx+uwsgi的实践</h4>

<p>nginx进程数会直接影响性能, 如何使用到的模块不会出现阻塞式的调用，应该有多少cpu就配多少worker_processes,否则才需要配置更多的进程数.
比如你的用户大量读取你的本地静态文件，并且服务器上面内存较少，硬盘的I/O调用可能会阻塞worker少量时间,那么就要多配</p>

<p>为了更好利用多核的优势,我绑定了worker和对应的内核:</p>

<p><code>python
worker_processes     4;
worker_cpu_affinity 0001 0010 0100 1000;
</code></p>
]]></content>
  </entry>
  
</feed>
